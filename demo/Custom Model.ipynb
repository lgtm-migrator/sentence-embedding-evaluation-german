{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4743dc34-766e-4e29-9e6f-6bf894f73c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97215c2-0daa-4d18-9b95-013791d9c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentence_embedding_evaluation_german as seeg\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_emb2vec import ConvToVec\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbef9d6-654d-4188-a052-9143061d8cd5",
   "metadata": {},
   "source": [
    "## (1) Instantiate your Embedding model\n",
    "First, you should load your pretrained embedding.\n",
    "\n",
    "Here we will generate a random embedding for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3cfc31-31ad-441e-869d-9970f7071a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random embedding\n",
    "emb_dim = 256\n",
    "vocab_sz = 128\n",
    "emb = torch.randn((vocab_sz, emb_dim), requires_grad=False)\n",
    "emb = torch.nn.Embedding.from_pretrained(emb)\n",
    "# assert emb.weight.requires_grad == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d877f18-a1e3-40ce-bd86-110169b6c8de",
   "metadata": {},
   "source": [
    "## (2a) Specify the preprocessing\n",
    "The `preprocessor` function converts a sentences as string into embedding vectors of numbers.\n",
    "\n",
    "Here we will convert the input strings with a nonsensical approach into IDs for the Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c4dc56-c9d8-4e06-801e-3ae869852d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN = 128\n",
    "padid = 128\n",
    "\n",
    "def preprocesser(batch: List[str], params: dict=None) -> List[List[List[float]]]:\n",
    "    \"\"\" Specify your embedding or pretrained encoder here\n",
    "    Paramters:\n",
    "    ----------\n",
    "    params : dict\n",
    "        The params dictionary\n",
    "    batch : List[str]\n",
    "        A list of sentence as string\n",
    "    Returns:\n",
    "    --------\n",
    "    List[List[List[float]]]\n",
    "        A list of embedded sequences\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for sent in batch:\n",
    "        # encode\n",
    "        try:\n",
    "            ids = torch.tensor([ord(c) % 128 for c in sent])\n",
    "        except:\n",
    "            print(sent)\n",
    "        enc = emb(ids)\n",
    "        # truncate & pad\n",
    "        h = torch.ones(size=(SEQLEN, enc.shape[1]), dtype=torch.int64) * padid\n",
    "        end = min(enc.shape[0], SEQLEN)\n",
    "        try:\n",
    "            h[:end, :] = enc[:end, :].detach()\n",
    "        except Exception as e:\n",
    "            raise Exception(e)\n",
    "        features.append(h)\n",
    "    features = torch.stack(features, dim=0)\n",
    "    features = features.type(torch.float32)\n",
    "    return features.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf9b68-d721-4221-a9c4-0cdc92ed953e",
   "metadata": {},
   "source": [
    "## (2b) Specify a Customer Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c2d10d-58be-4428-bdd1-e5abe4dc1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClassiferModel(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 embdim: int,\n",
    "                 output_size: int,  # nclasses\n",
    "                 *args, **kwargs):\n",
    "        super(CustomClassiferModel, self).__init__(*args, **kwargs)\n",
    "        # Self-MHA layer (=> this will overfit bcoz tiny datasets!)\n",
    "        #self.mha_pre = torch.nn.LayerNorm(embdim, elementwise_affine=True)\n",
    "        #self.mha_net = torch.nn.MultiheadAttention(\n",
    "        #    embed_dim=embdim, num_heads=8, batch_first=True, bias=False)\n",
    "        # 2D to 1D flattening\n",
    "        self.to1d_pre = torch.nn.LayerNorm(embdim, elementwise_affine=True)\n",
    "        # compute kernel size and output channel dim\n",
    "        self.to1d_net = ConvToVec(\n",
    "            seq_len=SEQLEN, emb_dim=embdim, num_output=256, trainable=False)\n",
    "        self.to1d_act = torch.nn.GELU()\n",
    "        # Final layer\n",
    "        self.final_pre = torch.nn.LayerNorm(256, elementwise_affine=True)\n",
    "        self.final_net = torch.nn.Linear(256, output_size, bias=False)\n",
    "        self.final_act = torch.nn.Softmax(dim=1)\n",
    "        # init params\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self) -> None:\n",
    "        torch.manual_seed(42)\n",
    "        # Self-MHA projections\n",
    "        #for param in self.mha_net.parameters():\n",
    "        #    torch.nn.init.xavier_normal_(param, gain=1.0)\n",
    "        # Final layer\n",
    "        torch.nn.init.xavier_normal_(self.final_net.weight, gain=1.0)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        # Self-MHA layer\n",
    "        #print(\"Inputs\", inputs.shape)\n",
    "        h = inputs\n",
    "        #h = self.mha_pre(h)\n",
    "        #h, _ = self.mha_net(query=h, value=h, key=h)\n",
    "        #h = h + inputs  # skip-conn\n",
    "        # print(\"MHA\", h.shape)\n",
    "        # 2D to 1D flattening\n",
    "        h = self.to1d_pre(h)\n",
    "        h = self.to1d_net(h)\n",
    "        h = self.to1d_act(h)\n",
    "        #print(\"Flatten\", h.shape)\n",
    "        # Final layer\n",
    "        h = self.final_pre(h)\n",
    "        h = self.final_net(h)\n",
    "        #print(\"Final\", h.shape)\n",
    "        return self.final_act(h)\n",
    "\n",
    "\n",
    "def mymodel(**kwargs):\n",
    "    return CustomClassiferModel(\n",
    "        embdim=kwargs['n_features'],\n",
    "        output_size=kwargs['n_classes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c4e13e2-a25f-45f7-9b02-f98f0f3adc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params: 68352\n"
     ]
    }
   ],
   "source": [
    "model = mymodel(n_features=emb_dim, n_classes=3)\n",
    "n = sum([m.numel() for m in model.parameters()])\n",
    "print(f\"Num params: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd310db5-7909-406a-b125-c37325b87105",
   "metadata": {},
   "source": [
    "## (3) Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02deec53-b58b-4d5f-ae37-77d69f2b4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'datafolder': '../datasets',\n",
    "    'bias': True,\n",
    "    'balanced': True,\n",
    "    'batch_size': 128, \n",
    "    'num_epochs': 5,  # Default: 500\n",
    "    # 'early_stopping': True,\n",
    "    # 'split_ratio': 0.2,  # if early_stopping=True\n",
    "    # 'patience': 5,  # if early_stopping=True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ed1f1-1bb2-4c61-b1ed-d57569436e48",
   "metadata": {},
   "source": [
    "## (4) Specify downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e0b877-752c-4bde-b4ac-c51b16496ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "# downstream_tasks = [\n",
    "#     'TOXIC', 'ENGAGE', 'FCLAIM', 'VMWE',\n",
    "#     'OL19-A', 'OL19-B', 'OL19-C',\n",
    "#     'OL18-A', 'OL18-B', \n",
    "#     'ABSD-1', 'ABSD-2', 'ABSD-3',\n",
    "#     'MIO-S', 'MIO-O', 'MIO-I', 'MIO-D', 'MIO-F', 'MIO-P', 'MIO-A',\n",
    "#     'SBCH-L', 'SBCH-S', 'ARCHI', 'LSDC'\n",
    "# ]\n",
    "\n",
    "# Group tasks\n",
    "# downstream_tasks = [\n",
    "#     'ABSD-2', 'MIO-S', 'SBCH-S',  # Sentiment analysis\n",
    "#     'ENGAGE', 'MIO-P',  # engaging/personal\n",
    "#     'FCLAIM', 'MIO-A',  # fact-claim (potential fake news), argumentative, reasoning\n",
    "#     'TOXIC', 'OL19-A', 'OL19-B', 'OL19-C', 'MIO-O', 'MIO-I',  # toxic\n",
    "# ]\n",
    "\n",
    "# Current favorites\n",
    "downstream_tasks = ['FCLAIM', 'VMWE', 'OL19-C', 'ABSD-2', 'MIO-P', 'ARCHI', 'LSDC']\n",
    "#downstream_tasks = ['FCLAIM', 'VMWE', 'OL19-C', 'ABSD-2', 'MIO-P', 'ARCHI']\n",
    "#downstream_tasks = ['FCLAIM']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f4e17-b4a9-4c99-b41d-17a7364d1ead",
   "metadata": {},
   "source": [
    "## (5) Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc1d65f-034e-45eb-9d9c-f8db94deb3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset: FCLAIM\n",
      "train:    3244 examples,  256 features\n",
      " test:     944 examples,  256 features\n",
      "epoch 1 | loss: 0.7135430368093344\n",
      "epoch 2 | loss: 0.7014878277595227\n",
      "epoch 3 | loss: 0.6915632234169886\n",
      "epoch 4 | loss: 0.6831112091357892\n",
      "epoch 5 | loss: 0.6759548943776351\n",
      "Load dataset: VMWE\n",
      "train:    6652 examples,  256 features\n",
      " test:    1447 examples,  256 features\n",
      "epoch 1 | loss: 0.7347636016515585\n",
      "epoch 2 | loss: 0.7263364998193887\n",
      "epoch 3 | loss: 0.7193957028480676\n",
      "epoch 4 | loss: 0.7130806021965467\n",
      "epoch 5 | loss: 0.7075265336495179\n",
      "Load dataset: OL19-C\n",
      "train:    1921 examples,  256 features\n",
      " test:     930 examples,  256 features\n",
      "epoch 1 | loss: 0.7554306797683239\n",
      "epoch 2 | loss: 0.7453916557133198\n",
      "epoch 3 | loss: 0.734691996127367\n",
      "epoch 4 | loss: 0.7224976681172848\n",
      "epoch 5 | loss: 0.7112742327153683\n",
      "Load dataset: ABSD-2\n",
      "train:   19432 examples,  256 features\n",
      " test:    2555 examples,  256 features\n",
      "epoch 1 | loss: 1.1387023000340712\n",
      "epoch 2 | loss: 1.1301173207006956\n",
      "epoch 3 | loss: 1.1227577022816007\n",
      "epoch 4 | loss: 1.1163032988184376\n",
      "epoch 5 | loss: 1.110547243764526\n",
      "Load dataset: MIO-P\n",
      "train:    4668 examples,  256 features\n",
      " test:    4668 examples,  256 features\n",
      "epoch 1 | loss: 0.7185773011800405\n",
      "epoch 2 | loss: 0.7044869983518446\n",
      "epoch 3 | loss: 0.6922709378036292\n",
      "epoch 4 | loss: 0.6814145365276852\n",
      "epoch 5 | loss: 0.671771391018017\n",
      "Load dataset: ARCHI\n",
      "train:   18809 examples,  256 features\n",
      " test:    4743 examples,  256 features\n",
      "epoch 1 | loss: 1.414451814022194\n",
      "epoch 2 | loss: 1.405220240151801\n",
      "epoch 3 | loss: 1.3991441215787614\n",
      "epoch 4 | loss: 1.394372348882714\n",
      "epoch 5 | loss: 1.3900302324165292\n",
      "Load dataset: LSDC\n",
      "train:   74140 examples,  256 features\n",
      " test:    8602 examples,  256 features\n",
      "epoch 1 | loss: 2.6373065825166373\n",
      "epoch 2 | loss: 2.6245873105937036\n",
      "epoch 3 | loss: 2.6153374610276057\n",
      "epoch 4 | loss: 2.605838710686256\n",
      "epoch 5 | loss: 2.5966162229406424\n",
      "CPU times: user 1h 17min 6s, sys: 8min 11s, total: 1h 25min 17s\n",
      "Wall time: 1h 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = seeg.evaluate(\n",
    "    downstream_tasks=downstream_tasks, \n",
    "    preprocesser=preprocesser, \n",
    "    modelbuilder=mymodel,\n",
    "    verbose=1,\n",
    "    **params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d70632-f1fa-4b9f-8f55-fa228c36668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dat = json.dumps(results, indent=2)\n",
    "# print(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e3482-6c13-43aa-8071-d7037e5b4e91",
   "metadata": {},
   "source": [
    "## (6) Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac84999e-8dae-44c7-8442-371d49a0c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task | Epochs | N train | N test\n",
      " FCLAIM:     5   3244    944\n",
      "   VMWE:     5   6652   1447\n",
      " OL19-C:     5   1921    930\n",
      " ABSD-2:     5  19432   2555\n",
      "  MIO-P:     5   4668   4668\n",
      "  ARCHI:     5  18809   4743\n",
      "   LSDC:     5  74140   8602\n"
     ]
    }
   ],
   "source": [
    "print(\"Task | Epochs | N train | N test\")\n",
    "for res in results:\n",
    "    print(f\"{res['task']:>7s}: {res['epochs']:5d} {res['train']['num']:6d} {res['test']['num']:6d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a9e87f-9401-441f-9b77-959be2860a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task | train | test\n",
      " FCLAIM:  0.623  0.595\n",
      "   VMWE:  0.617  0.610\n",
      " OL19-C:  0.578  0.541\n",
      " ABSD-2:  0.404  0.362\n",
      "  MIO-P:  0.594  0.586\n",
      "  ARCHI:  0.281  0.266\n",
      "   LSDC:  0.126  0.127\n"
     ]
    }
   ],
   "source": [
    "metric = 'acc'  # 'f1', 'f1-balanced', 'acc', 'acc-balanced'\n",
    "print('  Task | train | test')\n",
    "for res in results:\n",
    "    print(f\"{res['task']:>7s}: {res['train'][metric]:6.3f} {res['test'][metric]:6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9fbc769-02c7-4a86-be83-313d7f04a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task | train | test\n",
      " FCLAIM:  0.591  0.556\n",
      "   VMWE:  0.500  0.493\n",
      " OL19-C:  0.470  0.453\n",
      " ABSD-2:  0.327  0.285\n",
      "  MIO-P:  0.523  0.512\n",
      "  ARCHI:  0.264  0.249\n",
      "   LSDC:  0.079  0.091\n"
     ]
    }
   ],
   "source": [
    "metric = 'f1-balanced'  # 'f1', 'f1-balanced', 'acc', 'acc-balanced'\n",
    "print('  Task | train | test')\n",
    "for res in results:\n",
    "    print(f\"{res['task']:>7s}: {res['train'][metric]:6.3f} {res['test'][metric]:6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55202679-8bee-48b9-8d4a-6728d8c51706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCLAIM 944\n",
      "{'0': '630', '1': '314'}\n",
      "{'0': '594', '1': '350'}\n",
      "VMWE 1447\n",
      "{'1': '256', '0': '1191'}\n",
      "{'0': '950', '1': '497'}\n",
      "OL19-C 930\n",
      "{'0': '796', '1': '134'}\n",
      "{'1': '423', '0': '507'}\n",
      "ABSD-2 2555\n",
      "{'1': '1670', '0': '780', '2': '105'}\n",
      "{'2': '732', '0': '807', '1': '1016'}\n",
      "MIO-P 4668\n",
      "{'1': '812', '0': '3856'}\n",
      "{'0': '2631', '1': '2037'}\n",
      "ARCHI 4743\n",
      "{'2': '1177', '3': '1176', '1': '1199', '0': '1191'}\n",
      "{'1': '2130', '3': '1052', '0': '1063', '2': '498'}\n",
      "LSDC 8602\n",
      "{'13': '280', '6': '346', '12': '940', '3': '925', '2': '944', '1': '934', '11': '931', '0': '453', '10': '511', '5': '924', '4': '65', '8': '923', '9': '83', '7': '343'}\n",
      "{'11': '496', '2': '1850', '0': '749', '12': '241', '9': '362', '8': '357', '3': '285', '5': '990', '13': '288', '1': '1130', '10': '748', '4': '666', '6': '273', '7': '167'}\n"
     ]
    }
   ],
   "source": [
    "# class label distributions (inference)\n",
    "for res in results:\n",
    "    print(res['task'], res['test']['num'])\n",
    "    print(res['test']['distr-test'])\n",
    "    print(res['test']['distr-pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e7f8b38-81c0-477c-a63c-eb46b2a08fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCLAIM 3244\n",
      "{'0': '2141', '1': '1103'}\n",
      "{'0': '2007', '1': '1237'}\n",
      "VMWE 6652\n",
      "{'1': '1145', '0': '5507'}\n",
      "{'1': '2291', '0': '4361'}\n",
      "OL19-C 1921\n",
      "{'0': '1664', '1': '257'}\n",
      "{'1': '798', '0': '1123'}\n",
      "ABSD-2 19432\n",
      "{'2': '1179', '1': '13208', '0': '5045'}\n",
      "{'2': '5311', '1': '8049', '0': '6072'}\n",
      "MIO-P 4668\n",
      "{'0': '3855', '1': '813'}\n",
      "{'1': '2048', '0': '2620'}\n",
      "ARCHI 18809\n",
      "{'1': '4797', '3': '4407', '2': '4802', '0': '4803'}\n",
      "{'0': '3994', '1': '9207', '3': '3633', '2': '1975'}\n",
      "LSDC 74140\n",
      "{'12': '15019', '8': '7829', '5': '13506', '1': '5294', '11': '13227', '3': '11002', '2': '5704', '13': '346', '10': '749', '7': '382', '9': '143', '0': '469', '6': '377', '4': '93'}\n",
      "{'5': '8871', '10': '5629', '2': '19861', '9': '2998', '0': '5828', '1': '8043', '4': '5250', '11': '3864', '12': '2380', '3': '2506', '6': '2162', '8': '2988', '13': '2247', '7': '1513'}\n"
     ]
    }
   ],
   "source": [
    "# class label distribution (training)\n",
    "for res in results:\n",
    "    print(res['task'], res['train']['num'])\n",
    "    print(res['train']['distr-train'])\n",
    "    print(res['train']['distr-pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a7b0b-f295-4b80-a4b5-f2f5c06ef518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
